{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948f5aa7-e4e3-48b1-b800-85b8fad4dbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_num</th>\n",
       "      <th>vote_1</th>\n",
       "      <th>vote_2</th>\n",
       "      <th>vote_3</th>\n",
       "      <th>vote_4</th>\n",
       "      <th>vote_5</th>\n",
       "      <th>vote_6</th>\n",
       "      <th>vote_7</th>\n",
       "      <th>vote_8</th>\n",
       "      <th>vote_9</th>\n",
       "      <th>vote_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>953417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.008065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>953777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>953756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.273438</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>954195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.459016</td>\n",
       "      <td>0.188525</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>953903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.266129</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.137097</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_num  vote_1    vote_2    vote_3    vote_4    vote_5    vote_6  \\\n",
       "0     953417     0.0  0.000000  0.000000  0.040323  0.258065  0.403226   \n",
       "1     953777     0.0  0.023438  0.015625  0.023438  0.101562  0.312500   \n",
       "2     953756     0.0  0.015625  0.023438  0.070312  0.273438  0.390625   \n",
       "3     954195     0.0  0.008197  0.057377  0.213115  0.459016  0.188525   \n",
       "4     953903     0.0  0.008065  0.032258  0.040323  0.266129  0.403226   \n",
       "\n",
       "     vote_7    vote_8    vote_9   vote_10  \n",
       "0  0.185484  0.080645  0.024194  0.008065  \n",
       "1  0.273438  0.164062  0.062500  0.023438  \n",
       "2  0.156250  0.039062  0.015625  0.015625  \n",
       "3  0.049180  0.008197  0.000000  0.016393  \n",
       "4  0.137097  0.072581  0.024194  0.016129  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"data/labels.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2dec82-15be-43fb-9155-92ba5d240581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 184603, Val: 32578, Test: 38327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_num</th>\n",
       "      <th>vote_1</th>\n",
       "      <th>vote_2</th>\n",
       "      <th>vote_3</th>\n",
       "      <th>vote_4</th>\n",
       "      <th>vote_5</th>\n",
       "      <th>vote_6</th>\n",
       "      <th>vote_7</th>\n",
       "      <th>vote_8</th>\n",
       "      <th>vote_9</th>\n",
       "      <th>vote_10</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143953</th>\n",
       "      <td>684178</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.303665</td>\n",
       "      <td>0.340314</td>\n",
       "      <td>0.162304</td>\n",
       "      <td>0.036649</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>5.659686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43395</th>\n",
       "      <td>567633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.210784</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>6.259804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199848</th>\n",
       "      <td>932635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>6.077519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200572</th>\n",
       "      <td>71307</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.025455</td>\n",
       "      <td>0.076364</td>\n",
       "      <td>0.170909</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.203636</td>\n",
       "      <td>0.141818</td>\n",
       "      <td>0.061818</td>\n",
       "      <td>0.029091</td>\n",
       "      <td>0.029091</td>\n",
       "      <td>5.505455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142725</th>\n",
       "      <td>836507</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>5.890476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_num    vote_1    vote_2    vote_3    vote_4    vote_5    vote_6  \\\n",
       "143953     684178  0.015707  0.020942  0.010471  0.083770  0.303665  0.340314   \n",
       "43395      567633  0.000000  0.004902  0.014706  0.083333  0.191176  0.294118   \n",
       "199848     932635  0.000000  0.007752  0.000000  0.069767  0.255814  0.387597   \n",
       "200572      71307  0.007273  0.025455  0.076364  0.170909  0.254545  0.203636   \n",
       "142725     836507  0.019048  0.019048  0.042857  0.119048  0.214286  0.233333   \n",
       "\n",
       "          vote_7    vote_8    vote_9   vote_10  mean_score  \n",
       "143953  0.162304  0.036649  0.015707  0.010471    5.659686  \n",
       "43395   0.210784  0.137255  0.058824  0.004902    6.259804  \n",
       "199848  0.139535  0.085271  0.023256  0.031008    6.077519  \n",
       "200572  0.141818  0.061818  0.029091  0.029091    5.505455  \n",
       "142725  0.157143  0.128571  0.038095  0.028571    5.890476  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.split_utils import load_and_split_labels\n",
    "\n",
    "train_df, val_df, test_df = load_and_split_labels(\"data/labels.csv\")\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "076f8f76-9884-4bfc-8d73-1c1e56a37187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.split_utils import load_and_split_labels\n",
    "from utils.dataset import AestheticDataset\n",
    "from models.hybrid_model import HybridAestheticModel\n",
    "from utils.train import train_one_epoch, evaluate\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512da7f3-58b0-4164-8bce-426259f2cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels with split\n",
    "train_df, val_df, test_df = load_and_split_labels(\"data/labels.csv\")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((320, 240)),\n",
    "    transforms.RandomRotation(degrees=15),             # rotate randomly ±15 degrees\n",
    "    transforms.RandomHorizontalFlip(p=0.5),             # horizontal flip with 50% chance\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((320, 240)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "images_dir = \"data/images\"\n",
    "\n",
    "train_ds = AestheticDataset(train_df, images_dir, transform_train)\n",
    "val_ds = AestheticDataset(val_df, images_dir, transform)\n",
    "test_ds = AestheticDataset(test_df, images_dir, transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=128)\n",
    "test_loader = DataLoader(test_ds, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa077630-cb70-49ea-9679-bbd03e7fade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_gpu_garbage():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf56b21-90a5-4736-afbc-66f1e679d0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 121/1443 [23:49<4:20:22, 11.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mipc_collect()\n\u001b[0;32m     14\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m---> 15\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_one_epoch(model, train_loader, optimizer, device)\n\u001b[0;32m     16\u001b[0m val_loss, _, _ \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[0;32m     18\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[1;32m~\\Desktop\\LICENTA@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\proiect_licenta\\image_aesthetic_project\\utils\\train.py:9\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      8\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, hist, target \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[0;32m     10\u001b[0m     img, hist, target \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device), hist\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(img, hist)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\Desktop\\LICENTA@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\proiect_licenta\\image_aesthetic_project\\utils\\dataset.py:32\u001b[0m, in \u001b[0;36mAestheticDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     29\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m---> 32\u001b[0m     img_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     img_tensor \u001b[38;5;241m=\u001b[39m img\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mresize(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mantialias)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\torchvision\\transforms\\functional.py:477\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    475\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    476\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[1;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39mpil_interpolation)\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mresize(\u001b[38;5;28mtuple\u001b[39m(size[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), interpolation)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dsm\\Lib\\site-packages\\PIL\\Image.py:2328\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2316\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2317\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[0;32m   2318\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[0;32m   2319\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[0;32m   2320\u001b[0m         )\n\u001b[0;32m   2321\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2322\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2323\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2324\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2325\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2326\u001b[0m         )\n\u001b[1;32m-> 2328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mresize(size, resample, box))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridAestheticModel().to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "epochs = 10\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    collect_gpu_garbage()\n",
    "    \n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    collect_gpu_garbage()\n",
    "    \n",
    "    val_loss, _, _ = evaluate(model, val_loader, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # Save checkpoint if best val loss so far\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint_path = f\"best_model_epoch_{epoch+1}_val_loss_{val_loss:.4f}.pt\"\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Saved new best model checkpoint: {checkpoint_path}\")\n",
    "\n",
    "\n",
    "    # Free GPU memory cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c7d7d-c0d2-4035-b9d9-cd416e1068ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze your target distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(targets, bins=50)\n",
    "plt.title('Target Score Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca57c5c-6f98-4724-b654-c738d17524af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this to your training script\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/model_architecture')\n",
    "writer.add_graph(model, (dummy_input, dummy_hsv, dummy_rgb, dummy_lab, dummy_comp))\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
